### Huang said advancements in technology will help democratize artificial intelligence for everyone.

![](https://img-cdn.inc.com/image/upload/w_600,ar_16:9,c_fill,g_auto,q_auto:best/images/panoramic/NVIDIA-Jensen-Huang-inc_537332_npjqju.webp)

Founder and C.E.O. of NVIDIA Jensen Huang.

 Photo: Getty Images

[Jensen Huang](https://www.inc.com/ben-sherry/nvidia-founder-jensen-huang-on-how-a-close-call-with-failure-helps-him-dominate-ai.html) doesn't agree with OpenAI founder [Sam Altman's](https://www.inc.com/ben-sherry/sam-altman-raising-trillions-to-supercharge-ai-chipmaking.html) math.

During an [interview](https://www.youtube.com/@WorldGovSummit) at the World Government Summit in Dubai on Monday, the founder of AI computing giant Nvidia expressed skepticism at the need to raise $7 trillion to overhaul the AI-chip-making process--the amount recently floated by Altman. Explaining his reasoning, Huang noted that the technology behind artificial intelligence is constantly evolving and improving, which would drive costs down. Asked how many graphics processing units (GPUs) he could buy for $7 trillion, Huang answered, "all the GPUs, apparently," poking fun at Altman's figure.

"If you just assume computers aren't going to get any faster," Huang said, "you might come to the conclusion that we need 14 planets, three galaxies and four more suns to fuel all this, but computer architecture continues to advance."

Asked if the next era of artificial intelligence will be built on GPUs, a segment of which Nvidia holds roughly [80 percent market share](https://www.tomshardware.com/news/gpu-market-healthy-and-vibrant-in-q2-2023-report#:~:text=As%20for%20market%20shares%20and,a%20dominant%2080.2%25%20market%20share.), or some new type of technology, Huang pointed out that many of the other major tech companies are indeed working on their own proprietary chips that could serve as alternatives to GPUs. Microsoft is developing Maia, a customized silicon chip developed specifically to train large language models. Google, meanwhile, is working on tensor processing units, or TPUs, designed to accelerate machine learning workloads. And Meta is working on its own in-house chips, Reuters [reported](https://www.reuters.com/technology/meta-deploy-in-house-custom-chips-this-year-power-ai-drive-memo-2024-02-01/).

One of the things that makes Nvidia's approach to AI different from its potential competitors, according to Huang, is that its GPUs are available to "anybody on any platform," which Huang says is part and parcel with his ambitions to "democratize AI." Huang went on to claim that Nvidia is in "every cloud and data center, all the way out to autonomous systems and self-driving cars."

As new ways of constructing AI systems are invented, Huang suggested Nvidia will be able to be nimble and adapt. "All of these architectures can be created on Nvidia's flexible architecture, and because they're available literally everywhere," Huang says, "any researcher can get access to Nvidia's GPUs and invent the next generation." 

Top Tech

Sign up for our weekly roundup on the latest in tech